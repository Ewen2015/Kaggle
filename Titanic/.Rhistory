n2 <- dim(pop2)[1]
Spooled <- 1/(n-2) * ((n1-1)*S1 + (n2-1)*S2)
Spooled
admission %>% group_by(factor(Status)) %>% summarise(mean=mean(GPA), sd=sd(GMAT))
a <- solve(Spooled, mean1 - mean2)
mean1 <- apply(pop1[, 1:2], 2, mean)
mean2 <- apply(pop2[, 1:2], 2, mean)
a <- solve(Spooled, mean1 - mean2)
a
zij <- t(t(a) %*% t(admission[, 1:2]))
plot(zij, rep(1, n), col = admission[,3])
qplot(zij, rep(1, n), col = admission[,3])
qplot(zij, rep(1, n), col = factor(admission[,3]))
qplot(zij, rep(1, n), geom = "jitter", col = factor(admission[,3]))
qplot(zij, rep(1, n), geom = "point", col = factor(admission[,3]))
qplot(zij, rep(1, n), geom = "point", col = factor(admission[,3]), alpha = factor(admission[,3]))
qplot(zij, rep(1, n), geom = "point", col = factor(admission[,3]), alpha = range(0.4, 0.8)))
qplot(zij, rep(1, n), geom = "point", col = factor(admission[,3]))
p = qplot(zij, rep(1, n), geom = "point", col = factor(admission[,3]))
midpoint = t(mean1 - mean2) %*% solve(Spooled) %*% (mean1 + mean2)/2
midpoint
p = qplot(zij, rep(1, n), geom = "point", col = factor(admission[,3]))
p
plot(zij, rep(1, n), geom = "point", col = factor(admission[,3]))
plot(zij, rep(1, n), geom = "point", col = factor(admission[,3]), pch = 17)
plot(zij, rep(1, n), geom = "point", col = factor(admission[,3]), pch = 20)
grid()
abline(v=midpoint, lty=3)
abline(v=midpoint, lty=3, col = "red3")
abline(v=midpoint, lty=3, col = "red3", lwd = 2)
plot(zij, rep(1, n), geom = "point", col = factor(admission[,3]), pch = 20)
zij <- t(t(a) %*% t(admission[, 1:2]))
plot(zij, rep(1, n), geom = "point", col = factor(admission[,3]), pch = 20)
plot(zij, rep(1, n), col = factor(admission[,3]), pch = 20)
grid()
abline(v=midpoint, lty=3, col = "red3", lwd = 2)
t(a) %*% t(matrix(c(3, 500), nrow = 1))
qplot(zij, rep(1, n), col = factor(admission[,3]), pch = 20)
qplot(zij, rep(1, n), col = factor(admission[,3]))
plot(zij, rep(1, n), col = factor(admission[,3]), pch = 20)
grid()
abline(v=midpoint, lty=3, col = "red3", lwd = 2)
midpoint
t(a) %*% t(matrix(c(3, 500), nrow = 1))
score = t(a) %*% t(matrix(c(3, 500), nrow = 1))
ggplot(admission, aes(x=GPA, y=GMAT)) +
geom_point(aes(col = factor(Status))) +
geom_point(aes(x = 3, y = 500), color="red")
ggplot(admission, aes(x=GPA, y=GMAT)) +
geom_point(aes(col = factor(Status))) +
geom_point(aes(x = 3, y = 500), color="blue")
ggplot(admission, aes(x=GPA, y=GMAT)) +
geom_point(aes(col = factor(Status))) +
geom_point(aes(x = 3, y = 500), color="yellow")
a
fbDat <- read.table("football_data.txt", header = T)
a
lda.fit = lda(Status~., data = admission)
lad.fit
lda.fit
df = data.frame(zij, y = rep(1, n))
ggplot(data = df, aes(x = zij, y = y, col = factor(admission[,3])))
ggplot(data = df, aes(x = zij, y = y, col = factor(admission[,3]))) +
geom_points()
ggplot(data = df, aes(x = zij, y = y, col = factor(admission[,3]))) +
geom_point()
ggplot(data = df, aes(x = zij, y = y)) +
geom_point(aes(col = factor(admission[,3])))
ggplot(data = df, aes(x = zij, y = y)) +
geom_point(aes(col = factor(admission[,3]))) +
geom_point(aes(x = midpoint, y = 1), col = "yellow")
ggplot(data = df, aes(x = zij, y = y)) +
geom_point(aes(col = factor(admission[,3]))) +
geom_point(aes(x = midpoint, y = 1), col = "blue")
ggplot(data = df, aes(x = zij, y = y)) +
geom_point(aes(col = factor(admission[,3]))) +
geom_point(aes(x = midpoint, y = 1), col = "green")
ggplot(data = df, aes(x = zij, y = y)) +
geom_point(aes(col = factor(admission[,3]))) +
geom_point(aes(x = midpoint, y = 1), col = "yellow")
ggplot(data = df, aes(x = zij, y = y)) +
geom_point(aes(col = factor(admission[,3]))) +
geom_point(aes(x = midpoint, y = 1), col = "black")
ggplot(admission, aes(x=GPA, y=GMAT)) +
geom_point(aes(col = factor(Status))) +
geom_point(aes(x = 3, y = 500), color="yellow") +
geom_abline(intercept = 37, slope = -5)
lda.fit
score
lda.fit
3.071443853*3+500*0.004733621
trans = preProcess(admission[,-1], c("BoxCox", "center", "scale"))
predictorsTrans = data.frame(trans = predict(trans, admission[,-1]))
predict(lda.fit, newdata = c(3, 500))
newdata = data.frame(GPA = 3, GMAT = 500)
predict(lda.fit, newdata)
a
a <- solve(Spooled, mean2 - mean1)
a
1
a
a <- solve(Spooled, mean1 - mean2)
a
midpoint
midpoint/0.01101639
7.14806424/0.01101639
geom_abline(intercept = 2404.07, slope = -648.8572)
ggplot(admission, aes(x=GPA, y=GMAT)) +
geom_point(aes(col = factor(Status))) +
geom_point(aes(x = 3, y = 500), color="yellow") +
geom_abline(intercept = 2404.07, slope = -648.8572)
a
a[GMAT]
a[2]
ggplot(admission, aes(x=GPA, y=GMAT)) +
geom_point(aes(col = factor(Status))) +
geom_point(aes(x = 3, y = 500), color="yellow") +
geom_abline(intercept = midpoint/a[2], slope = -a[1]/a[2], col = green)
ggplot(admission, aes(x=GPA, y=GMAT)) +
geom_point(aes(col = factor(Status))) +
geom_point(aes(x = 3, y = 500), color="yellow") +
geom_abline(intercept = midpoint/a[2], slope = -a[1]/a[2], col = "green")
require(MASS)
lda.fit = lda(data$RootStock~., data = predictorsTrans)
lda.fit = lda(data$RootStock~., data = data)
lda.fit
lda.fit$scaling
require(knitr)
kable(lda.fit$scaling)
kable(lda.fit$scaling, align = "l")
lda.fit
z <- as.matrix(data[,-1]) %*% lda.fit$scaling
plot(z, pch = rep(1:3, 1, each = 30), col = rep(1:3, 1, each = 30))
qplot(z, pch = rep(1:3, 1, each = 30), col = rep(1:3, 1, each = 30))
str(z)
head(z)
z[,1]
df = data.frame(LD1 = z[,1], LD2 = z[,2], RootStock = data[,1])
ggplot(data = df, aes(x = LD1, y = LD2)) +
geom_point(aes(col = factor(RootStock)))
ggplot(data = df, aes(x = LD1, y = LD2)) +
geom_point(aes(col = factor(RootStock), shape =factor(RootStock)))
ggplot(data = df, aes(x = LD1, y = LD2)) +
geom_point(aes(col = factor(RootStock), shape =factor(RootStock)), size = 2.5)
newdata = c(1.09, 2.69, 4.38, 1.29)
newdata = data.frame(c(1.09, 2.69, 4.38, 1.29))
predict(lda.fit, newdata)
newdata = data.frame(Y1 = 1.09, Y2= 2.69, Y3 = 4.38, Y4 = 1.29))
newdata = data.frame(Y1 = 1.09, Y2= 2.69, Y3 = 4.38, Y4 = 1.29)
predict(lda.fit, newdata)
pred = predict(lda.fit, newdata)
pred$posterior[3]
kable(pred$posterior)
kable(pred$posterior, align = "l")
ggplot(data = df, aes(x = LD1, y = LD2)) +
geom_point(aes(col = factor(RootStock), shape =factor(RootStock)), size = 2.5) +
geom_point(aes(x = pred$x[1], y = pred$x[2]), size = 3)
ggplot(data = df, aes(x = LD1, y = LD2)) +
geom_point(aes(col = factor(RootStock), shape =factor(RootStock)), size = 2.5)
y = pred$x[2]
pred$x[2]
pred$x[1]
data = read.table("/Users/ewenwang/Dropbox/CSU-MAS/STAA 574/Notes/rootstock.txt", head = T)
lda.fit = lda(data$RootStock~., data = data)
kable(lda.fit$scaling, align = "l")
newdata = data.frame(Y1 = 1.09, Y2= 2.69, Y3 = 4.38, Y4 = 1.29)
pred = predict(lda.fit, newdata)
kable(pred$posterior, align = "l")
pred
ggplot(data = df, aes(x = LD1, y = LD3)) +
geom_point(aes(col = factor(RootStock), shape =factor(RootStock)), size = 2.5) +
geom_point(aes(x = pred$x[1], y = pred$x[2]), size = 3)
df = data.frame(LD1 = z[,1], LD2 = z[,2], LD3 = z[,3], LD4 = z[,4], RootStock = data[,1])
ggplot(data = df, aes(x = LD1, y = LD3)) +
geom_point(aes(col = factor(RootStock), shape =factor(RootStock)), size = 2.5) +
geom_point(aes(x = pred$x[1], y = pred$x[2]), size = 3)
kable(pred$posterior, align = "l")
ggplot(data = df, aes(x = LD1, y = LD3)) +
geom_point(aes(col = factor(RootStock), shape =factor(RootStock)), size = 2.5)
ggplot(data = df, aes(x = LD1, y = LD4)) +
geom_point(aes(col = factor(RootStock), shape =factor(RootStock)), size = 2.5)
kable(lda.fit$scaling, align = "l")
lda.fit
ggplot(data = df, aes(x = LD1, y = LD2)) +
geom_point(aes(col = factor(RootStock), shape =factor(RootStock)), size = 2.5)
df = data.frame(LD1 = z[,1], LD2 = z[,2], RootStock = data[,1])
ggplot(data = df, aes(x = LD1, y = LD2)) +
geom_point(aes(col = factor(RootStock), shape =factor(RootStock)), size = 2.5) +
geom_point(aes(x = pred$x[1], y = pred$x[2]), size = 3)
kable(pred$posterior, align = "l")
zNew <- newData %*% ldaOut$scaling
zNew <- newdata %*% ldafit$scaling
zNew <- newdata %*% lda.fit$scaling
newdata = c(1.09, 2.69, 4.38, 1.29)
zNew <- newdata %*% lda.fit$scaling
zNew
znew <- newdata %*% lda.fit$scaling
ggplot(data = df, aes(x = LD1, y = LD2)) +
geom_point(aes(col = factor(RootStock), shape =factor(RootStock)), size = 2.5) +
geom_point(aes(x = znew[1], y = znew[2]), col = red, size = 3)
ggplot(data = df, aes(x = LD1, y = LD2)) +
geom_point(aes(col = factor(RootStock), shape =factor(RootStock)), size = 2.5) +
geom_point(aes(x = znew[1], y = znew[2]), col = "red", size = 3)
geom_point(aes(x = znew[1], y = znew[2]), col = "red", size = 3, shape = 3)
ggplot(data = df, aes(x = LD1, y = LD2)) +
geom_point(aes(col = factor(RootStock), shape =factor(RootStock)), size = 2.5) +
geom_point(aes(x = znew[1], y = znew[2]), col = "red", size = 3, shape = 3)
kable(pred$posterior, align = "l")
library(adegenet)
install.packages("adegenet")
library(adegenet)
grp <- find.clusters(data[,-1]), max.n.clust = 6)
data = read.table("/Users/ewenwang/Dropbox/CSU-MAS/STAA 574/Notes/rootstock.txt", head = T)
x = data[, -1]
grp <- find.clusters(x, max.n.clust = 6)
grp$grp
grp = find.clusters(x, max.n.clust = 6)
dapc1 <- dapc(x, grp$grp)
scatter(dapc1)
grp = find.clusters(x, max.n.clust = 6)
dapc1 <- dapc(x, grp$grp)
scatter(dapc1)
xnew <- data[,-1] %*% lda.fit$scaling
load("/Users/ewenwang/Dropbox/CSU-MAS/STAA 577/Homework/Xtrain.rdata")
load("/Users/ewenwang/Dropbox/CSU-MAS/STAA 577/Homework/Ytrain.rdata")
View(Xtrain)
str(Xtrian)
str(Xtrain)
head(Xtrain[,200:204])
dat = data.frame(Xtrain, Ytrain)
library(h2o)
localH2O <- h2o.init(ip = "localhost", port = 54321, startH2O = TRUE)
dat_h2o <- as.h2o(localH2O, dat, key = 'dat')
dat = data.frame(Xtrain, Ytrain) # combine the X and Y
dat_h2o <- as.h2o(localH2O, dat, key = 'dat')
dat_h2o <- as.h2o(localH2O, dat)
dat_h2o <- as.h2o(localH2O, dat, destination_frame = 'dat')
dat_h2o <- as.h2o(localH2O, destination_frame = 'dat')
?as.h2o
dat_h2o <- as.h2o(dat, destination_frame = 'dat')
model <-
h2o.deeplearning(x = 1:255,  # column numbers for predictors
y = 256,   # column number for label
data = dat_h2o, # data in H2O format
activation = "TanhWithDropout", # or 'Tanh'
input_dropout_ratio = 0.2, # % of inputs dropout
hidden_dropout_ratios = c(0.5,0.5,0.5), # % for nodes dropout
balance_classes = TRUE,
hidden = c(50,50,50), # three layers of 50 nodes
epochs = 100) # max. no. of epochs
model <-
h2o.deeplearning(x = 1:255,  # column numbers for predictors
y = 256,   # column number for label
data = train_h2o, # data in H2O format
activation = "TanhWithDropout", # or 'Tanh'
input_dropout_ratio = 0.2, # % of inputs dropout
hidden_dropout_ratios = c(0.5,0.5,0.5), # % for nodes dropout
balance_classes = TRUE,
hidden = c(50,50,50), # three layers of 50 nodes
epochs = 100) # max. no. of epochs
?h2o.deeplearning
model <-
h2o.deeplearning(x = 1:255,  # column numbers for predictors
y = 256,   # column number for label
data = dat, # data in H2O format
activation = "TanhWithDropout", # or 'Tanh'
input_dropout_ratio = 0.2, # % of inputs dropout
hidden_dropout_ratios = c(0.5,0.5,0.5), # % for nodes dropout
balance_classes = TRUE,
hidden = c(50,50,50), # three layers of 50 nodes
epochs = 100) # max. no. of epochs
model <-
h2o.deeplearning(
model_id = "model",
training_frame = dat_h2o,
validation_frame = valid,   ## validation dataset: used for scoring and early stopping
x = 1:255,
y = 256,
#activation="Rectifier",  ## default
#hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each
epochs = 1,
variable_importances = T)    ## not enabled by default
model <-
h2o.deeplearning(
model_id = "model",
training_frame = dat_h2o,
x = 1:255,
y = 256,
#activation="Rectifier",  ## default
#hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each
epochs = 1,
variable_importances = T)    ## not enabled by default
model <-
h2o.deeplearning(
model_id = "model",
training_frame = dat_h2o,
x = 1:255,
y = 256,
activation = "TanhWithDropout", # or 'Tanh'
input_dropout_ratio = 0.2, # % of inputs dropout
hidden_dropout_ratios = c(0.5,0.5,0.5), # % for nodes dropout
hidden = c(50,50,50), # three layers of 50 nodes
epochs = 100,
variable_importances = T)    ## not enabled by default
summary(model)
load("/Users/ewenwang/Dropbox/CSU-MAS/STAA 577/Homework/Xtest.rdata")
?h2o.predict
h2o_yhat_test <- h2o.predict(model, Xtest)
dat_h2o_test <- as.h2o(Xtest, destination_frame = "Xtest")
h2o_yhat_test <- h2o.predict(model, dat_h2o_test)
df_yhat_test <- as.data.frame(h2o_yhat_test)
if(yourName == 'firstLast'){
print('fill in your name!')
}else{
fName = paste(c(yourName,'_Predictions.txt'),collapse='')
write.table(Yhat,file=fName,row.names=FALSE,col.names=FALSE)
}
yourName = "enqunWang"
#write.table
if(yourName == 'firstLast'){
print('fill in your name!')
}else{
fName = paste(c(yourName, '_Predictions.txt'), collapse = '')
write.table(df_yhat_test, file = fName, row.names = FALSE, col.names = FALSE)
}
yhat = read.table("enqunWang_Predictions.txt")
str(yhat)
?h20.predict
?h2o.predict
str(df_yhat_test)
localH2O = h2o.init(ip = "localhost", port = 54321, startH2O = TRUE, Xmx = '2g')
?h2o.init
localH2O = h2o.init(ip = "localhost", port = 54321, startH2O = TRUE, max_mem_size = "2g")
updata.packages("h2o")
update.packages("h2o")
localH2O = h2o.init(ip = "localhost", port = 54321, startH2O = TRUE, max_mem_size = "2g")
dat = data.frame(Xtrain, Ytrain) # combine the X and Y
dat_h2o <- as.h2o(dat, destination_frame = 'dat')
dat_h2o_test <- as.h2o(Xtest, destination_frame = "Xtest")
model <-
h2o.deeplearning(
model_id = "model",
training_frame = dat_h2o,
x = 1:255,
y = 256,
activation = "TanhWithDropout", # or 'Tanh'
input_dropout_ratio = 0.2, # % of inputs dropout
hidden_dropout_ratios = c(0.5,0.5,0.5), # % for nodes dropout
hidden = c(50,50,50), # three layers of 50 nodes
epochs = 100,
variable_importances = T)    ## not enabled by default
summary(model)
h2o_yhat_test <- h2o.predict(model, dat_h2o_test)
## Converting H2O format into data frame
df_yhat_test <- as.data.frame(h2o_yhat_test)
str(df_yhat_test)
yourName = "enqunWang"
#write.table
if(yourName == 'firstLast'){
print('fill in your name!')
}else{
fName = paste(c(yourName, '_Predictions.txt'), collapse = '')
write.table(df_yhat_test, file = fName, row.names = FALSE, col.names = FALSE)
}
yhat = read.table("enqunWang_Predictions.txt")
str(yhat)
if(yourName == 'firstLast'){
print('fill in your name!')
}else{
fName = paste(c(yourName, '_Predictions.txt'), collapse = '')
write.table(df_yhat_test[,1], file = fName, row.names = FALSE, col.names = FALSE)
}
yhat = read.table("enqunWang_Predictions.txt")
str(yhat)
which(yhat == "fraud")
fraud.idex = which(yhat == "fraud")
length(fraud.idex)
fraud.amount = length(fraud.idex)
fraud.index = which(yhat == "fraud")
fraud.index
fraud.amount
risk = fraud.amount/sum(yhat)
yhat = read.table("enqunWang_Predictions.txt")
str(yhat)
risk = fraud.amount/dim(yhat)[1]
risk
model <-
h2o.deeplearning(
model_id = "model",
training_frame = dat_h2o,
x = 1:255,
y = 256,
activation = "TanhWithDropout", # or 'Tanh'
input_dropout_ratio = 0.2, # % of inputs dropout
hidden_dropout_ratios = c(0.5,0.5,0.5), # % for nodes dropout
hidden = c(200, 200, 200), # three layers of 50 nodes
epochs = 750,
variable_importances = T)    ## not enabled by default
model <-
h2o.deeplearning(
model_id = "model",
training_frame = dat_h2o,
x = 1:255,
y = 256,
activation = "TanhWithDropout", # or 'Tanh'
input_dropout_ratio = 0.2, # % of inputs dropout
hidden_dropout_ratios = c(0.5,0.5,0.5), # % for nodes dropout
hidden = c(200, 200), # three layers of 50 nodes
epochs = 750,
variable_importances = T)
model <-
h2o.deeplearning(
model_id = "model",
training_frame = dat_h2o,
x = 1:255,
y = 256,
activation = "TanhWithDropout", # or 'Tanh'
input_dropout_ratio = 0.2, # % of inputs dropout
hidden_dropout_ratios = c(0.5,0.5,0.5), # % for nodes dropout
hidden = c(50, 50, 50), # three layers of 50 nodes
epochs = 750,
variable_importances = T)
summary(model)
h2o_yhat_test <- h2o.predict(model, dat_h2o_test)
## Converting H2O format into data frame
df_yhat_test <- as.data.frame(h2o_yhat_test)
str(df_yhat_test)
model <-
h2o.deeplearning(
model_id = "model",
training_frame = dat_h2o,
x = 1:255,
y = 256,
activation = "TanhWithDropout", # or 'Tanh'
input_dropout_ratio = 0.2, # % of inputs dropout
hidden_dropout_ratios = c(0.5,0.5,0.5), # % for nodes dropout
hidden = c(50, 50, 50), # three layers of 50 nodes
epochs = 100,
variable_importances = T)    ## not enabled by default
summary(model)
h2o_yhat_test <- h2o.predict(model, dat_h2o_test)
## Converting H2O format into data frame
df_yhat_test <- as.data.frame(h2o_yhat_test)
str(df_yhat_test)
#write.table
if(yourName == 'firstLast'){
print('fill in your name!')
}else{
fName = paste(c(yourName, '_Predictions.txt'), collapse = '')
write.table(df_yhat_test[,1], file = fName, row.names = FALSE, col.names = FALSE)
}
yhat = read.table("enqunWang_Predictions.txt")
str(yhat)
fraud.index = which(yhat == "fraud")
fraud.amount = length(fraud.index)
risk = fraud.amount/dim(yhat)[1]
fraud.amount
risk
dat_h2o_train_X <- as.h2o(Xtrain, destination_frame = "Xtrain")
dat_h2o_train_Y <- as.h2o(Ytrain, destination_frame = "Ytrain")
h2o_yhat_train <- h2o.predict(model, dat_h2o_train_X)
df_yhat_train <- as.data.frame(h2o_yhat_train)
str(df_yhat_test)
df_yhat_train <- as.data.frame(h2o_yhat_train)[,1]
str(df_yhat_test)
df_yhat_train <- df_yhat_train[,1]
df_yhat_train <- as.data.frame(h2o_yhat_train)
df_yhat_train <- df_yhat_train[,1]
str(df_yhat_test)
str(df_yhat_test[,1])
h2o_yhat_train <- h2o.predict(model, dat_h2o_train_X)
## Converting H2O format into data frame
df_yhat_train <- as.data.frame(h2o_yhat_train)
df_yhat_train <- df_yhat_train[,1]
str(h2o_yhat_train)
str(df_yhat_train)
miss.class =function(pred.class,true.class,produceOutput=FALSE){
confusion.mat = table(pred.class,true.class)
if(produceOutput){
return(1-sum(diag(confusion.mat))/sum(confusion.mat))
}
else{
print('miss-class')
print(1-sum(diag(confusion.mat))/sum(confusion.mat))
print('confusion mat')
print(confusion.mat)
return(1-sum(diag(confusion.mat))/sum(confusion.mat))
}
miss.class(df_yhat_train, Ytrain)
sum(which(Ytrain == "fraud"))/sum(Ytain)
sum(which(Ytrain == "fraud"))/sum(Ytrain)
Ytrain == "fraud"
sum(Ytrain == "fraud")
sum(Ytrain == "fraud")/length(Ytrain)
require(bookdown)
bookdown::render_book("index.Rmd",  bookdown::html_chapters())
require(devtools)
devtools::install_github("csgillespie/efficientR")
bookdown::render_book("index.Rmd",  bookdown::html_chapters())
install.packages("benchmarkme")
devtools::install_github("csgillespie/efficientR")
setwd("/Users/ewenwang/Dropbox/Data Science/Kaggle/Titanic")
d <- read.csv("train.csv",head=T)
d[ d == "?" ] <- NA
d$Survived  <- as.factor( d$Survived ) #
d$Pclass  <- as.factor( d$Pclass )
d$Age <- as.numeric( as.character( d$Age ) )
d$TicketNr <- as.numeric( as.character( d$TicketNr ) )
d$Ticket <- as.numeric( as.character( d$Ticket ) )
data = read.csv("train.csv", header = T)
View(data)
data[ data == "?" ] <- NA
