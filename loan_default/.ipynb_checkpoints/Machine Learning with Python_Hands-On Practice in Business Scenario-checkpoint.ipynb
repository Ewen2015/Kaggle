{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\" style=\"margin-top: 1em;\"><ul class=\"toc-item\"><li><span><a href=\"#Machine-Learning-with-Python:-Hands-On-Practice-in-Business-Scenario\" data-toc-modified-id=\"Machine-Learning-with-Python:-Hands-On-Practice-in-Business-Scenario-1\">Machine Learning with Python: Hands-On Practice in Business Scenario</a></span><ul class=\"toc-item\"><li><span><a href=\"#Loan-Default-Prediction-(LDP)-Competition-Introduction\" data-toc-modified-id=\"Loan-Default-Prediction-(LDP)-Competition-Introduction-1.1\">Loan Default Prediction (LDP) Competition Introduction</a></span></li><li><span><a href=\"#Data-Description\" data-toc-modified-id=\"Data-Description-1.2\">Data Description</a></span></li><li><span><a href=\"#Results-Evaluation\" data-toc-modified-id=\"Results-Evaluation-1.3\">Results Evaluation</a></span></li><li><span><a href=\"#Assignment\" data-toc-modified-id=\"Assignment-1.4\">Assignment</a></span></li><li><span><a href=\"#Task-1:-Exploratory-data-analysis\" data-toc-modified-id=\"Task-1:-Exploratory-data-analysis-1.5\">Task 1: Exploratory data analysis</a></span></li><li><span><a href=\"#Task-2:-Classification-w/o-feature-engineering\" data-toc-modified-id=\"Task-2:-Classification-w/o-feature-engineering-1.6\">Task 2: Classification w/o feature engineering</a></span></li><li><span><a href=\"#Task-3:-Classification-w/-feature-engineering\" data-toc-modified-id=\"Task-3:-Classification-w/-feature-engineering-1.7\">Task 3: Classification w/ feature engineering</a></span></li><li><span><a href=\"#Task-4:-Classification-plus-regression-and-submit-the-results-to-the-forum\" data-toc-modified-id=\"Task-4:-Classification-plus-regression-and-submit-the-results-to-the-forum-1.8\">Task 4: Classification plus regression and submit the results to the forum</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning with Python: Hands-On Practice in Business Scenario\n",
    "\n",
    "**Wang, En Qun EwenWangSH@cn.ibm.com**\n",
    "\n",
    "## Loan Default Prediction (LDP) Competition Introduction\n",
    "\n",
    "This competition asks you to determine whether a loan will default, as well as the loss incurred if it does default. Unlike traditional finance-based approaches to this problem, where one distinguishes between good or bad counterparties in a binary way, we seek to anticipate and incorporate both the default and the severity of the losses that result. In doing so, we are building a bridge between traditional banking, where we are looking at reducing the consumption of economic capital, to an asset-management perspective, where we optimize on the risk to the financial investor.\n",
    "\n",
    "This competition is sponsored by researchers at Imperial College London.\n",
    "\n",
    "![image](https://kaggle2.blob.core.windows.net/competitions/kaggle/3756/media/icl_logo.gif)\n",
    "\n",
    "## Data Description\n",
    "\n",
    "This data corresponds to a set of financial transactions associated with individuals. The data has been standardized, detrended, and anonymized. You are provided with over two hundred thousand observations and nearly 800 features.  Each observation is independent from the previous. \n",
    "\n",
    "For each observation, it was recorded whether a default was triggered. In case of a default, the loss was measured. This quantity lies between 0 and 100. It has been normalized, considering that the notional of each transaction at inception is 100. For example, a loss of 60 means that only 40 is reimbursed. If the loan did not default, the loss was 0. You are asked to predict the losses for each observation in the test set.\n",
    "\n",
    "Missing feature values have been kept as is, so that the competing teams can really use the maximum data available, implementing a strategy to fill the gaps if desired. Note that some variables may be categorical (e.g. $f776$ and $f777$).\n",
    "\n",
    "The competition sponsor has worked to remove time-dimensionality from the data. However, the observations are still listed in order from old to new in the training set. In the test set they are in random order.\n",
    "\n",
    "Please go to [Kaggle](https://www.kaggle.com/c/loan-default-prediction/data) and download the training and test data.\n",
    "\n",
    "\n",
    "## Results Evaluation\n",
    "\n",
    "This competition is evaluated on the mean absolute error (MAE):\n",
    "\n",
    "$$MAE = \\frac{1}{n} \\sum_{i=1}^{n}{|y_i - \\hat{y_i}|}$$\n",
    "\n",
    "where\n",
    "\n",
    "$n$ is the number of rows\n",
    "\n",
    "$\\hat{y_i}$ is the predicted loss\n",
    "\n",
    "$y_i$ is the actual loss\n",
    "\n",
    "\n",
    "## Assignment\n",
    "\n",
    "A two-step-process to predict the loss is an intuitive solution to this competition: **classification to predict the defaulter** and **regression to predict the loss** ($log(loss+1)$ to be correct). \n",
    "\n",
    "In this hands-on practice, we will divide the competition into four tasks as following:\n",
    "\n",
    "- Task 1: Exploratory data analysis.\n",
    "- Task 2: Classification w/o feature engineering.\n",
    "- Task 3: Classification w/ feature engineering.\n",
    "- Task 4: Classification plus regression and submit the results to the forum.\n",
    "\n",
    "You may complete **Task 0** and **Task 1** during the training and the rest two tasks after the class. \n",
    "\n",
    "---\n",
    "\n",
    "## Task 1: Exploratory data analysis\n",
    "\n",
    "Exploratory data analysis (EDA) is an approach to analyzing data sets to summarize their main characteristics, often with visual methods. “EDA” is a critical first step in analyzing the data from an experiment. Here are the main reasons we use EDA:\n",
    "\n",
    "- detection of mistakes\n",
    "- checking of assumptions\n",
    "- preliminary selection of appropriate models\n",
    "- determining relationships among the explanatory variables, and\n",
    "- assessing the direction and rough size of relationships between explanatory and outcome variables.\n",
    "\n",
    "Loosely speaking, any method of looking at data that does not include formal statistical modeling and inference falls under the term exploratory data analysis.\n",
    "\n",
    "**Task: Do as much as possible EDA w/ training data.**\n",
    "\n",
    "**Requirement: Please provide rational EDA w/ descriptions. Never drop a chart or graph w/o any explanation!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-28T15:34:50.976758Z",
     "start_time": "2017-12-28T15:34:29.441880Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "wd = '/Users/ewenwang/Documents/practice_data'  # use your work directory\n",
    "file_train = 'loan_default.csv'                 # use your training set file name\n",
    "os.chdir(wd)\n",
    "\n",
    "train = pd.read_csv(file_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-28T14:49:47.635882Z",
     "start_time": "2017-12-28T14:49:47.584288Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 105471 entries, 0 to 105470\n",
      "Columns: 771 entries, id to loss\n",
      "dtypes: float64(653), int64(99), object(19)\n",
      "memory usage: 620.4+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>...</th>\n",
       "      <th>f770</th>\n",
       "      <th>f771</th>\n",
       "      <th>f772</th>\n",
       "      <th>f773</th>\n",
       "      <th>f774</th>\n",
       "      <th>f775</th>\n",
       "      <th>f776</th>\n",
       "      <th>f777</th>\n",
       "      <th>f778</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>10</td>\n",
       "      <td>0.686842</td>\n",
       "      <td>1100</td>\n",
       "      <td>3</td>\n",
       "      <td>13699</td>\n",
       "      <td>7201.0</td>\n",
       "      <td>4949.0</td>\n",
       "      <td>126.75</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>2.14</td>\n",
       "      <td>-1.54</td>\n",
       "      <td>1.18</td>\n",
       "      <td>0.1833</td>\n",
       "      <td>0.7873</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>121</td>\n",
       "      <td>10</td>\n",
       "      <td>0.782776</td>\n",
       "      <td>1100</td>\n",
       "      <td>3</td>\n",
       "      <td>84645</td>\n",
       "      <td>240.0</td>\n",
       "      <td>1625.0</td>\n",
       "      <td>123.52</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0.54</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.1926</td>\n",
       "      <td>-0.6787</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>126</td>\n",
       "      <td>10</td>\n",
       "      <td>0.500080</td>\n",
       "      <td>1100</td>\n",
       "      <td>3</td>\n",
       "      <td>83607</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>1527.0</td>\n",
       "      <td>127.76</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>2.89</td>\n",
       "      <td>-1.73</td>\n",
       "      <td>1.04</td>\n",
       "      <td>0.2521</td>\n",
       "      <td>0.7258</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>134</td>\n",
       "      <td>10</td>\n",
       "      <td>0.439874</td>\n",
       "      <td>1100</td>\n",
       "      <td>3</td>\n",
       "      <td>82642</td>\n",
       "      <td>7542.0</td>\n",
       "      <td>1730.0</td>\n",
       "      <td>132.94</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1.29</td>\n",
       "      <td>-0.89</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.2498</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>109</td>\n",
       "      <td>9</td>\n",
       "      <td>0.502749</td>\n",
       "      <td>2900</td>\n",
       "      <td>4</td>\n",
       "      <td>79124</td>\n",
       "      <td>89.0</td>\n",
       "      <td>491.0</td>\n",
       "      <td>122.72</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>6.11</td>\n",
       "      <td>-3.82</td>\n",
       "      <td>2.51</td>\n",
       "      <td>0.2282</td>\n",
       "      <td>-0.5399</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 771 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   f1  f2        f3    f4  f5     f6      f7      f8      f9  ...   f770  \\\n",
       "0   1  126  10  0.686842  1100   3  13699  7201.0  4949.0  126.75  ...      5   \n",
       "1   2  121  10  0.782776  1100   3  84645   240.0  1625.0  123.52  ...      6   \n",
       "2   3  126  10  0.500080  1100   3  83607  1800.0  1527.0  127.76  ...     13   \n",
       "3   4  134  10  0.439874  1100   3  82642  7542.0  1730.0  132.94  ...      4   \n",
       "4   5  109   9  0.502749  2900   4  79124    89.0   491.0  122.72  ...     26   \n",
       "\n",
       "   f771  f772  f773    f774    f775  f776  f777  f778  loss  \n",
       "0  2.14 -1.54  1.18  0.1833  0.7873     1     0     5     0  \n",
       "1  0.54 -0.24  0.13  0.1926 -0.6787     1     0     5     0  \n",
       "2  2.89 -1.73  1.04  0.2521  0.7258     1     0     5     0  \n",
       "3  1.29 -0.89  0.66  0.2498  0.7119     1     0     5     0  \n",
       "4  6.11 -3.82  2.51  0.2282 -0.5399     0     0     5     0  \n",
       "\n",
       "[5 rows x 771 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.info()                       # get the information of the training set\n",
    "train.head()                       # take a look at the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-28T14:59:32.922747Z",
     "start_time": "2017-12-28T14:59:26.533063Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>...</th>\n",
       "      <th>f770</th>\n",
       "      <th>f771</th>\n",
       "      <th>f772</th>\n",
       "      <th>f773</th>\n",
       "      <th>f774</th>\n",
       "      <th>f775</th>\n",
       "      <th>f776</th>\n",
       "      <th>f777</th>\n",
       "      <th>f778</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>105471.000000</td>\n",
       "      <td>105471.000000</td>\n",
       "      <td>105471.000000</td>\n",
       "      <td>105471.000000</td>\n",
       "      <td>105471.000000</td>\n",
       "      <td>105471.000000</td>\n",
       "      <td>105471.000000</td>\n",
       "      <td>105289.000000</td>\n",
       "      <td>105370.000000</td>\n",
       "      <td>105471.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>105471.000000</td>\n",
       "      <td>105471.000000</td>\n",
       "      <td>105471.000000</td>\n",
       "      <td>105471.000000</td>\n",
       "      <td>104407.000000</td>\n",
       "      <td>103946.000000</td>\n",
       "      <td>105471.000000</td>\n",
       "      <td>105471.000000</td>\n",
       "      <td>105471.000000</td>\n",
       "      <td>105471.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>52736.000000</td>\n",
       "      <td>134.603171</td>\n",
       "      <td>8.246883</td>\n",
       "      <td>0.499066</td>\n",
       "      <td>2678.488874</td>\n",
       "      <td>7.354533</td>\n",
       "      <td>47993.704317</td>\n",
       "      <td>2974.336018</td>\n",
       "      <td>2436.363718</td>\n",
       "      <td>134.555225</td>\n",
       "      <td>...</td>\n",
       "      <td>17.422543</td>\n",
       "      <td>5.800976</td>\n",
       "      <td>-4.246788</td>\n",
       "      <td>3.273059</td>\n",
       "      <td>0.233852</td>\n",
       "      <td>0.014797</td>\n",
       "      <td>0.310246</td>\n",
       "      <td>0.322847</td>\n",
       "      <td>175.951589</td>\n",
       "      <td>0.799585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>30446.999458</td>\n",
       "      <td>14.725467</td>\n",
       "      <td>1.691535</td>\n",
       "      <td>0.288752</td>\n",
       "      <td>1401.010943</td>\n",
       "      <td>5.151112</td>\n",
       "      <td>35677.136048</td>\n",
       "      <td>2546.551085</td>\n",
       "      <td>2262.950221</td>\n",
       "      <td>13.824682</td>\n",
       "      <td>...</td>\n",
       "      <td>18.548936</td>\n",
       "      <td>6.508555</td>\n",
       "      <td>4.828265</td>\n",
       "      <td>3.766746</td>\n",
       "      <td>0.073578</td>\n",
       "      <td>1.039439</td>\n",
       "      <td>0.462597</td>\n",
       "      <td>0.467567</td>\n",
       "      <td>298.294043</td>\n",
       "      <td>4.321120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>1100.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>106.820000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-43.160000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-18.439600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>26368.500000</td>\n",
       "      <td>124.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.248950</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>11255.000000</td>\n",
       "      <td>629.000000</td>\n",
       "      <td>746.000000</td>\n",
       "      <td>124.290000</td>\n",
       "      <td>...</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.480000</td>\n",
       "      <td>-5.700000</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>0.198400</td>\n",
       "      <td>-0.704275</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>52736.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.498267</td>\n",
       "      <td>2200.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>76530.000000</td>\n",
       "      <td>2292.000000</td>\n",
       "      <td>1786.000000</td>\n",
       "      <td>128.460000</td>\n",
       "      <td>...</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>3.570000</td>\n",
       "      <td>-2.600000</td>\n",
       "      <td>1.990000</td>\n",
       "      <td>0.251800</td>\n",
       "      <td>0.375400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>79103.500000</td>\n",
       "      <td>148.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.749494</td>\n",
       "      <td>3700.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>80135.000000</td>\n",
       "      <td>4679.000000</td>\n",
       "      <td>3411.000000</td>\n",
       "      <td>149.080000</td>\n",
       "      <td>...</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>7.700000</td>\n",
       "      <td>-1.010000</td>\n",
       "      <td>4.440000</td>\n",
       "      <td>0.283600</td>\n",
       "      <td>0.737100</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>105471.000000</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>7900.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>88565.000000</td>\n",
       "      <td>9968.000000</td>\n",
       "      <td>11541.000000</td>\n",
       "      <td>172.950000</td>\n",
       "      <td>...</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>58.120000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34.040000</td>\n",
       "      <td>0.473700</td>\n",
       "      <td>11.092000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1212.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 752 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id             f1             f2             f3  \\\n",
       "count  105471.000000  105471.000000  105471.000000  105471.000000   \n",
       "mean    52736.000000     134.603171       8.246883       0.499066   \n",
       "std     30446.999458      14.725467       1.691535       0.288752   \n",
       "min         1.000000     103.000000       1.000000       0.000006   \n",
       "25%     26368.500000     124.000000       8.000000       0.248950   \n",
       "50%     52736.000000     129.000000       9.000000       0.498267   \n",
       "75%     79103.500000     148.000000       9.000000       0.749494   \n",
       "max    105471.000000     176.000000      11.000000       0.999994   \n",
       "\n",
       "                  f4             f5             f6             f7  \\\n",
       "count  105471.000000  105471.000000  105471.000000  105289.000000   \n",
       "mean     2678.488874       7.354533   47993.704317    2974.336018   \n",
       "std      1401.010943       5.151112   35677.136048    2546.551085   \n",
       "min      1100.000000       1.000000       0.000000       1.000000   \n",
       "25%      1500.000000       4.000000   11255.000000     629.000000   \n",
       "50%      2200.000000       4.000000   76530.000000    2292.000000   \n",
       "75%      3700.000000      10.000000   80135.000000    4679.000000   \n",
       "max      7900.000000      17.000000   88565.000000    9968.000000   \n",
       "\n",
       "                  f8             f9      ...                 f770  \\\n",
       "count  105370.000000  105471.000000      ...        105471.000000   \n",
       "mean     2436.363718     134.555225      ...            17.422543   \n",
       "std      2262.950221      13.824682      ...            18.548936   \n",
       "min         1.000000     106.820000      ...             2.000000   \n",
       "25%       746.000000     124.290000      ...             5.000000   \n",
       "50%      1786.000000     128.460000      ...            11.000000   \n",
       "75%      3411.000000     149.080000      ...            23.000000   \n",
       "max     11541.000000     172.950000      ...           168.000000   \n",
       "\n",
       "                f771           f772           f773           f774  \\\n",
       "count  105471.000000  105471.000000  105471.000000  104407.000000   \n",
       "mean        5.800976      -4.246788       3.273059       0.233852   \n",
       "std         6.508555       4.828265       3.766746       0.073578   \n",
       "min         0.000000     -43.160000       0.000000       0.000000   \n",
       "25%         1.480000      -5.700000       0.740000       0.198400   \n",
       "50%         3.570000      -2.600000       1.990000       0.251800   \n",
       "75%         7.700000      -1.010000       4.440000       0.283600   \n",
       "max        58.120000       0.000000      34.040000       0.473700   \n",
       "\n",
       "                f775           f776           f777           f778  \\\n",
       "count  103946.000000  105471.000000  105471.000000  105471.000000   \n",
       "mean        0.014797       0.310246       0.322847     175.951589   \n",
       "std         1.039439       0.462597       0.467567     298.294043   \n",
       "min       -18.439600       0.000000       0.000000       2.000000   \n",
       "25%        -0.704275       0.000000       0.000000      19.000000   \n",
       "50%         0.375400       0.000000       0.000000      40.000000   \n",
       "75%         0.737100       1.000000       1.000000     104.000000   \n",
       "max        11.092000       1.000000       1.000000    1212.000000   \n",
       "\n",
       "                loss  \n",
       "count  105471.000000  \n",
       "mean        0.799585  \n",
       "std         4.321120  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max       100.000000  \n",
       "\n",
       "[8 rows x 752 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Help:**\n",
    "\n",
    "`pandas_profiling` generates profile reports from a `pandas` DataFrame. The `df.describe()` function is great but a little basic for serious exploratory data analysis.\n",
    "\n",
    "For each column the following statistics - if relevant for the column type - are presented in an interactive HTML report:\n",
    "\n",
    "- Essentials: type, unique values, missing values\n",
    "- Quantile statistics like minimum value, Q1, median, Q3, maximum, range, interquartile range\n",
    "- Descriptive statistics like mean, mode, standard deviation, sum, median absolute deviation, coefficient of variation, kurtosis, skewness\n",
    "- Most frequent values\n",
    "- Histogram\n",
    "\n",
    "Go to [Github](https://github.com/JosPolfliet/pandas-profiling) to find more information about `pandas_profiling`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_profiling as pp\n",
    "\n",
    "# pp.ProfileReport(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, it's your turn!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Classification w/o feature engineering\n",
    "\n",
    "We will explore classification algorithms you have learn in the morning.  \n",
    "\n",
    "**Task: Try any classification algorithm you would like to and evaluate them with AUC score.**\n",
    "\n",
    "**Requirement: Start from simple statistical models like logistic regression first, and then dive deeper with algorithms like SVM, bagging, boosting, or even artificial neural network.**\n",
    "\n",
    "**Notes:** \n",
    "1. All normal algorithms can be found in the package `sklearn`.\n",
    "2. If you already familiar with the normal machine learning algorithms, please try some more efficient algorithm products like `xgboost` and `lightgbm`.\n",
    "3. All algorithms mentioned above are just a single model or a single algorithm with ensemble models; to go further in machine learning algorithm, please try some more complicated technique like **stacking**.\n",
    "\n",
    "Training set and validation set are prepared as following:\n",
    "\n",
    "**Help:**\n",
    "\n",
    "If you are confused with the difference among training set, test set, and validation set, please go to [Wikipedia](https://en.wikipedia.org/wiki/Training,_test,_and_validation_sets) for more information or just ask our training instructors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-28T15:36:07.793423Z",
     "start_time": "2017-12-28T15:36:07.334181Z"
    }
   },
   "outputs": [],
   "source": [
    "# generate target variable for the classification task\n",
    "\n",
    "default = train['loss']\n",
    "default[default>0] = 1\n",
    "train['default'] = default\n",
    "\n",
    "target = 'default'\n",
    "features = [x for x in train.columns if x not in [target, 'id', 'loss']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-28T15:36:11.562297Z",
     "start_time": "2017-12-28T15:36:10.191299Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "seed = 2018\n",
    "test_size = 0.3\n",
    "\n",
    "dtrain, dvalid = train_test_split(train, test_size = test_size, random_state = seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try your algorithms and fit your models on `train` and predict on `valid`.\n",
    "\n",
    "The following is a simple logistic regression model with the golden feature. \n",
    "\n",
    "**Note:** The golden feature is generated from feature engineering, which will be covered in the next task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-28T15:43:27.418872Z",
     "start_time": "2017-12-28T15:43:27.169457Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "golden_feature = dtrain['f274'] - dtrain['f528']               # generated from feature engineering\n",
    "golden_feature = pd.DataFrame(golden_feature.fillna(golden_feature.median()))\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(golden_feature, dtrain[target])\n",
    "\n",
    "\n",
    "train_prob = lr.predict_proba(golden_feature)[:, 1]\n",
    "train_auc = metrics.roc_auc_score(dtrain[target], train_prob)\n",
    "\n",
    "valid_gf = dvalid['f274'] - dvalid['f528']             \n",
    "valid_gf = pd.DataFrame(valid_gf.fillna(valid_gf.median()))\n",
    "\n",
    "valid_prob = lr.predict_proba(valid_gf)[:, 1]\n",
    "valid_auc = metrics.roc_auc_score(dvalid[target], valid_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-28T15:43:35.748875Z",
     "start_time": "2017-12-28T15:43:35.742522Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Report:\n",
      "AUC_Train:  0.936762776912\n",
      "AUC_Valid:  0.939375926472\n"
     ]
    }
   ],
   "source": [
    "print('Model Report:')\n",
    "print('AUC_Train: ', train_auc)\n",
    "print('AUC_Valid: ', valid_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above practice with logistic regression and golden feature already achieves a pretty good result, which largely thanks to the feature engineering. Please feel free to use the golden feature above and explore more machine learning algorithms. \n",
    "\n",
    "Now, it's your turn!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Task 3: Classification w/ feature engineering\n",
    "\n",
    "You may already benefit the feature engineering from the golden feature in the task above. We will do more feature engineering task in this section.\n",
    "\n",
    "Feature engineering is the process of using domain knowledge of the data to create features that make \n",
    "machine learning algorithms work. Feature engineering is fundamental to the application of machine learning, \n",
    "and is both difficult and expensive. The need for manual feature engineering can be obviated by automated \n",
    "feature learning.\n",
    "\n",
    "Feature engineering is an informal topic, but it is considered essential in applied machine learning.\n",
    "\n",
    "**Task:**\n",
    "\n",
    "1. Summary the data types in the dataset. You may need some EDA to explore it. Please refer to the EDA task.\n",
    "2. Try to find possible ways to transform raw data into the one that machine learning algorithms can handle with.\n",
    "3. Generate reasonable features with your expert knowledge and possible techniques. Illustrate why you do so.\n",
    "4. Rebuild your classification models with data after the feature engineering.\n",
    "\n",
    "**Requirement: Please provide rational FE w/ descriptions. Do everything w/ a reason and necessary explanation!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Task 4: Classification plus regression and submit the results to the forum\n",
    "\n",
    "So far you have completed the most difficult part of this competition -- classification, your next task is to do regression with defaulters generated from classification. \n",
    "\n",
    "The linear regression is one of the most classical topic in statistics. If you would like to learn more about linear regression, please check it on [Wikipedia](https://en.wikipedia.org/wiki/Linear_regression). \n",
    "\n",
    "Now, it's your turn!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When all of above are done, it's time to submit your result to the [Kaggle](https://www.kaggle.com/c/loan-default-prediction). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
